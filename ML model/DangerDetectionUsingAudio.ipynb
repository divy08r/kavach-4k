{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5xfWMNXeE2a"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.models import load_model\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c_7hsuEXeN1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/Dataset/Audio_dataset.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "0inzY-A0eNtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the folder structure\n",
        "data_dir = 'Audio_dataset'\n",
        "classes = ['Danger', 'Normal']"
      ],
      "metadata": {
        "id": "rgQ6AJwRA1D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess audio data\n",
        "def load_and_preprocess_data(data_dir, classes, target_shape=(256, 256)):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.mp3'):\n",
        "                file_path = os.path.join(class_dir, filename)\n",
        "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "                mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "                data.append(mel_spectrogram)\n",
        "                labels.append(i)\n",
        "    return np.array(data), np.array(labels)"
      ],
      "metadata": {
        "id": "1UX2UitxeFwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "data, labels = load_and_preprocess_data(data_dir, classes)\n",
        "labels = to_categorical(labels, num_classes=len(classes))\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qcLDjaPAB0Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Creation\n",
        "input_shape = X_train[0].shape\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_layer = Dense(len(classes), activation='softmax')(x)\n",
        "model = Model(input_layer, output_layer)"
      ],
      "metadata": {
        "id": "7OiFFSQ-B2_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6tl93m_cetFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "f5OUFdxZe5Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy)"
      ],
      "metadata": {
        "id": "wvgZ5mDve8Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('audio_classification_model.h5')"
      ],
      "metadata": {
        "id": "fgZ5TivJe_Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = load_model('audio_classification_model.h5')\n",
        "# Define the target shape for input spectrograms\n",
        "target_shape = (256, 256)\n",
        "# Define your class labels\n",
        "classes = ['Danger', 'Normal']"
      ],
      "metadata": {
        "id": "shEZg187ikA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and classify an audio file\n",
        "def test_audio(file_path, model):\n",
        "    # Load and preprocess the audio file\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "    mel_spectrogram = tf.reshape(mel_spectrogram, (1,) + target_shape + (1,))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(mel_spectrogram)\n",
        "\n",
        "    # Get the class probabilities\n",
        "    class_probabilities = predictions[0]\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = np.argmax(class_probabilities)\n",
        "\n",
        "    return class_probabilities, predicted_class_index"
      ],
      "metadata": {
        "id": "QTblLJ9ni8bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test an audio file\n",
        "test_audio_file = '/content/check_danger9.mp3'\n",
        "class_probabilities, predicted_class_index = test_audio(test_audio_file, model)\n",
        "\n",
        "# Display results for all classes\n",
        "for i, class_label in enumerate(classes):\n",
        "    probability = class_probabilities[i]\n",
        "    print(f'Class: {class_label}, Probability: {probability:.4f}')"
      ],
      "metadata": {
        "id": "C0wmN0CECo1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display the predicted class and accuracy\n",
        "predicted_class = classes[predicted_class_index]\n",
        "accuracy = class_probabilities[predicted_class_index]\n",
        "print(f'The audio is classified as: {predicted_class}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "cWC1zYoxCoxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "toCiWRSODhXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}